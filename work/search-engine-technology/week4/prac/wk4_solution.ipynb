{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a194c2a0",
   "metadata": {},
   "source": [
    "# Week 4 solutions\n",
    "<author>&copy; Professor Yuefeng Li </author> "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a96ef76",
   "metadata": {},
   "source": [
    "## Task 1: Stemming \n",
    "Use porter2 stemming algorithm to update your last week function parse_doc(input, stops) to ensure all terms are in stemmed forms. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "904764d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob, os\n",
    "import string\n",
    "from stemming.porter2 import stem  ## for wk 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "48679352",
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_doc(fn, stop_ws):\n",
    "    coll = {}    \n",
    "    #os.chdir(inputpath)\n",
    "    #myfile=open('741299newsML.xml')\n",
    "    myfile=open(fn)\n",
    "    #myfile=open('C:\\\\python27\\\\py_CAB431_201\\\\data\\\\741299newsML.xml', 'r')\n",
    "    curr_doc = {}\n",
    "    start_end = False\n",
    "    #docid='741299'\n",
    "    file_=myfile.readlines()\n",
    "    #word_count = 0 #wk3\n",
    "    for line in file_:\n",
    "        line = line.strip()\n",
    "        #print(line)\n",
    "        if(start_end == False):\n",
    "            if line.startswith(\"<newsitem \"):\n",
    "                for part in line.split():\n",
    "                    if part.startswith(\"itemid=\"):\n",
    "                        docid = part.split(\"=\")[1].split(\"\\\"\")[1]\n",
    "                        break  \n",
    "            if line.startswith(\"<text>\"):\n",
    "                start_end = True  \n",
    "        elif line.startswith(\"</text>\"):\n",
    "            break\n",
    "        else:\n",
    "            line = line.replace(\"<p>\", \"\").replace(\"</p>\", \"\")\n",
    "            line = line.translate(str.maketrans('','', string.digits)).translate(str.maketrans(string.punctuation, ' '*len(string.punctuation)))\n",
    "            line = line.replace(\"\\\\s+\", \" \")\n",
    "            for term in line.split():\n",
    "                #word_count += 1 #wk3\n",
    "                term = stem(term.lower()) ## for wk 4\n",
    "                #term = term.lower() #wk3\n",
    "                if len(term) > 2 and term not in stop_words: #wk3\n",
    "                    try:\n",
    "                        curr_doc[term] += 1\n",
    "                    except KeyError:\n",
    "                        curr_doc[term] = 1\n",
    "    myfile.close()\n",
    "    dn=Doc_Node((docid,curr_doc), None)\n",
    "    return(dn)\n",
    "    # return a tuple, the first element is the number of words in <text> and\n",
    "    # the second one is a dirctionary that includes only one pair of doc_id and a disctionary of term_frequency pairs "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "275c02c0",
   "metadata": {},
   "source": [
    "## Task 2: \n",
    "Define a Doc_Node Class: \n",
    "\n",
    "class Doc_Node: \n",
    "    \n",
    "    def __init__(self, data, next=None):\n",
    "\n",
    "    self.data=data \n",
    "\n",
    "    self.next=next\n",
    " \n",
    "where $data$ attribute stores the document’s information, i.e., tuple (docid, curr_doc), and docid is the ‘itemid’ in <newsitem>; curr_doc is a dictionary of term_frequency pairs (review last week workshop if you do not understand the tuple)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2f9dd7b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Node class of document\n",
    "class Doc_Node:\n",
    "    def __init__(self, data, next=None):\n",
    "        self.data=data\n",
    "        self.next=next\n",
    "\n",
    "#Linked List calss   \n",
    "class List_Docs:\n",
    "    def __init__(self, hnode):\n",
    "        self.head=hnode\n",
    "\n",
    "    def insert(self, nnode):\n",
    "        if self.head != None:\n",
    "            p = self.head\n",
    "            while p.next != None:\n",
    "                p=p.next\n",
    "            p.next=nnode\n",
    "            \n",
    "    def lprint(self):\n",
    "        if self.head != None:\n",
    "            p = self.head\n",
    "            while p!= None:\n",
    "                print('(ID-'+p.data[0] + ':',end =\" \" )\n",
    "                print(str(len(p.data[1]))+' terms)',end =\" \" )\n",
    "                if p.next != None:\n",
    "                    print ('-->', end=\" \")\n",
    "                p=p.next\n",
    "        else:\n",
    "            print('The list is empty!')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "510df674",
   "metadata": {},
   "source": [
    "## Task 3: \n",
    "Design the main function to read several xml files and represent each file as a node, then create a linked\n",
    "list to link all nodes together. You need to update function parse_doc(), e.g., arguments or return value, and\n",
    "then use Doc_Node and List_Docs classes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e2b67c64",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------Stems and Their Frequencies in doc 6146.xml-----\n",
      "argentin : 1\n",
      "bond : 1\n",
      "slight : 2\n",
      "higher : 1\n",
      "small : 1\n",
      "technic : 2\n",
      "bounc : 2\n",
      "wednesday : 1\n",
      "amid : 1\n",
      "low : 1\n",
      "volum : 1\n",
      "trader : 3\n",
      "larg : 1\n",
      "foreign : 1\n",
      "bank : 1\n",
      "open : 1\n",
      "expect : 3\n",
      "price : 1\n",
      "chang : 1\n",
      "much : 1\n",
      "dure : 1\n",
      "session : 1\n",
      "market : 2\n",
      "move : 1\n",
      "news : 1\n",
      "percent : 1\n",
      "dollar : 1\n",
      "denomin : 1\n",
      "bocon : 1\n",
      "prevision : 1\n",
      "due : 2\n",
      "rose : 2\n",
      "argentina : 2\n",
      "frb : 1\n",
      "quot : 2\n",
      "general : 1\n",
      "uncertainti : 1\n",
      "point : 1\n",
      "event : 1\n",
      "wait : 1\n",
      "includ : 1\n",
      "passag : 1\n",
      "govern : 1\n",
      "new : 1\n",
      "econom : 1\n",
      "measur : 1\n",
      "through : 1\n",
      "congress : 1\n",
      "now : 1\n",
      "until : 1\n",
      "earli : 1\n",
      "octob : 1\n",
      "addit : 1\n",
      "await : 1\n",
      "meet : 1\n",
      "friday : 1\n",
      "between : 1\n",
      "economi : 1\n",
      "minist : 1\n",
      "roqu : 1\n",
      "fernandez : 1\n",
      "intern : 1\n",
      "monetari : 1\n",
      "fund : 1\n",
      "deleg : 1\n",
      "fiscal : 1\n",
      "deficit : 1\n",
      "axel : 1\n",
      "bugg : 1\n",
      "bueno : 1\n",
      "air : 1\n",
      "newsroom : 1\n",
      "----- The linked list for docs 6146.xml and 741299newsML.xml------\n",
      "(ID-6146: 72 terms) --> (ID-741299: 96 terms) "
     ]
    }
   ],
   "source": [
    "# if __name__ == '__main__':\n",
    "\n",
    "import sys\n",
    "    #if len(sys.argv) != 2:\n",
    "    #    sys.stderr.write(\"USAGE: %s <coll-file>\\n\" % sys.argv[0])\n",
    "    #    sys.exit()\n",
    "\n",
    "stopwords_f = open('common-english-words.txt', 'r') # wk3\n",
    "stop_words = stopwords_f.read().split(',')\n",
    "stopwords_f.close()\n",
    "#os.chdir(sys.argv[1])\n",
    "fn1='6146.xml'\n",
    "fn2='741299newsML.xml'\n",
    "\n",
    "# test Task 1\n",
    "xn = parse_doc(fn1,stop_words)\n",
    "print('------Stems and Their Frequencies in doc '+ fn1 +'-----')\n",
    "doc = (xn.data)[1]\n",
    "    #doc = {k: v for k, v in sorted(doc.items(), reverse=False)}\n",
    "for stem1, freq in doc.items(): #cannot use stem as it is a reserved word\n",
    "    print(stem1 + ' : '+ str(freq))\n",
    "    \n",
    "#Test Task 2 and Task 3\n",
    "xn1 = parse_doc(fn1,stop_words)\n",
    "xn2 = parse_doc(fn2,stop_words)\n",
    "ll= List_Docs(xn1)\n",
    "ll.insert(xn2)\n",
    "print('----- The linked list for docs '+ fn1 +' and ' + fn2 +'------')\n",
    "ll.lprint()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66f0a68a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
