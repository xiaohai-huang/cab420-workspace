{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "import string\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_doc(file_path, stop_words):\n",
    "    word_count = 0\n",
    "    doc_id = \"\"\n",
    "    term_frequency = {}\n",
    "    with open(file_path, \"r\") as file:\n",
    "        text_start = False\n",
    "        for line in file:\n",
    "            # remove \\n and spaces\n",
    "            line = line.strip()\n",
    "\n",
    "            # process the content of <text></text>\n",
    "           \n",
    "\n",
    "            # obtain itemid\n",
    "            if not doc_id:\n",
    "                if line.startswith(\"<newsitem \"):\n",
    "                    for part in line.split():\n",
    "                        if part.startswith(\"itemid=\"):\n",
    "                            doc_id = part.split(\"=\")[1].strip(\"\\\"\")\n",
    "\n",
    "            # look for the content of <text></text>\n",
    "            if line.startswith(\"<text>\"):\n",
    "                text_start = True\n",
    "                continue\n",
    "            elif line.startswith(\"</text>\"):\n",
    "                text_start = False\n",
    "                break\n",
    "\n",
    "            if text_start:\n",
    "                # remove p tags\n",
    "                line = line.replace(\"<p>\",\"\").replace(\"</p>\", \"\")\n",
    "                \n",
    "                # remove digits and punctuations\n",
    "                line = line.translate(str.maketrans(\"\", \"\", string.digits))\n",
    "                line = line.translate(str.maketrans(string.punctuation, \" \"* len(string.punctuation)))\n",
    "\n",
    "                # remove extra white spaces\n",
    "                line = re.sub(r\"\\s+\", \" \", line)\n",
    "                for term in line.split():\n",
    "                    word_count += 1\n",
    "                    term = term.lower()\n",
    "                    print(term)\n",
    "                    if len(term) > 2 and (term not in stop_words):\n",
    "                        if term in term_frequency:\n",
    "                            term_frequency[term] += 1\n",
    "                        else:\n",
    "                            term_frequency[term] = 1\n",
    "\n",
    "    return (word_count, {doc_id: term_frequency})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "argentine\n",
      "bonds\n",
      "were\n",
      "slightly\n",
      "higher\n",
      "in\n",
      "a\n",
      "small\n",
      "technical\n",
      "bounce\n",
      "wednesday\n",
      "amid\n",
      "low\n",
      "volume\n",
      "a\n",
      "trader\n",
      "at\n",
      "a\n",
      "large\n",
      "foreign\n",
      "bank\n",
      "said\n",
      "there\n",
      "was\n",
      "a\n",
      "slight\n",
      "technical\n",
      "bounce\n",
      "at\n",
      "the\n",
      "opening\n",
      "and\n",
      "he\n",
      "did\n",
      "not\n",
      "expect\n",
      "prices\n",
      "to\n",
      "change\n",
      "much\n",
      "during\n",
      "the\n",
      "session\n",
      "as\n",
      "no\n",
      "market\n",
      "moving\n",
      "news\n",
      "is\n",
      "expected\n",
      "the\n",
      "percent\n",
      "dollar\n",
      "denominated\n",
      "bocon\n",
      "previsional\n",
      "due\n",
      "rose\n",
      "to\n",
      "argentina\n",
      "s\n",
      "frb\n",
      "due\n",
      "rose\n",
      "to\n",
      "quot\n",
      "there\n",
      "is\n",
      "general\n",
      "uncertainty\n",
      "quot\n",
      "said\n",
      "the\n",
      "trader\n",
      "pointing\n",
      "to\n",
      "all\n",
      "the\n",
      "events\n",
      "the\n",
      "market\n",
      "is\n",
      "waiting\n",
      "for\n",
      "including\n",
      "the\n",
      "passage\n",
      "of\n",
      "the\n",
      "government\n",
      "s\n",
      "new\n",
      "economic\n",
      "measures\n",
      "through\n",
      "congress\n",
      "which\n",
      "is\n",
      "now\n",
      "not\n",
      "expected\n",
      "until\n",
      "early\n",
      "october\n",
      "in\n",
      "addition\n",
      "traders\n",
      "are\n",
      "awaiting\n",
      "a\n",
      "meeting\n",
      "friday\n",
      "between\n",
      "economy\n",
      "minister\n",
      "roque\n",
      "fernandez\n",
      "and\n",
      "an\n",
      "international\n",
      "monetary\n",
      "fund\n",
      "delegation\n",
      "on\n",
      "argentina\n",
      "s\n",
      "fiscal\n",
      "deficit\n",
      "axel\n",
      "bugge\n",
      "buenos\n",
      "aires\n",
      "newsroom\n",
      "Document itemid: 6146 contains: 133 words and 75 terms\n"
     ]
    }
   ],
   "source": [
    "stopwords_f = open('common-english-words.txt', 'r') # wk3\n",
    "stop_words = stopwords_f.read().split(',')\n",
    "x = parse_doc(\"6146.xml\",stop_words)\n",
    "\n",
    "for doc in x[1].items():\n",
    "        print('Document itemid: '+ doc[0]+ ' contains: '+ str(x[0]) + ' words and ' + str(len(doc[1])) + ' terms')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<_io.TextIOWrapper name='6146.xml' mode='r' encoding='UTF-8'>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nb     233    aaa\n"
     ]
    }
   ],
   "source": [
    "line = \"nb     233    aaa\"\n",
    "line = line.replace(\"\\\\s+\", \"99999\")\n",
    "print(line)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'nb 233 aaa'"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "re.sub(r\"\\s+\", \" \", line)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "12328a4b23be1c7cec08b06706c715be0163e3764006085465cbbe8cea75b2e4"
  },
  "kernelspec": {
   "display_name": "Python 3.9.5 ('cab420-env')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
