{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "source": [
    "# CAB420, Week 2 Practical - Template\n",
    "\n",
    "**Note, as the three questions in this weeks practical build on one another, all solutions are in the one script**\n",
    "\n",
    "## Problem 1. Overfitting Linear Regression\n",
    "In the week 1 practical, you developed a model to predict cyclist counts at a single counter. Using the same data and starting from the initial model before terms were removed, overcomplicate it such that it overfits to the training data. The easiest way to do this is by including a large number of higher order (i.e. interaction, quadratic and higher order polynomial) terms.\n",
    "\n",
    "Verify that the model has overfit through evaluating on the validation and testing datasets, and compare it's performance to the simple model that you started with.\n",
    "\n",
    "## Problem 2. Ridge Regression\n",
    "Apply ridge regression to your two models (the simple model from Week 1, and the overfitting model from Problem 1 of this week). Using the validation set, select the best value of $\\lambda$ for each model. For the selected model:\n",
    "* Compute the $R^2$ and adjusted $R^2$, and draw a qqplot to assess the models validity;\n",
    "* Compute the RMSE on the test set and compare the performance with the linear models.\n",
    "\n",
    "## Problem 3. Lasso Regression\n",
    "Apply lasso regression to your two models (the simple model from Week 1, and the overfitting model from Problem 1 of this week). Using the validation set, select the best value of $\\lambda$ for each model. For the selected model:\n",
    "* Compute the $R^2$ and adjusted $R^2$ (make sure to consider how many terms are removed by lasso), and draw a qqplot to assess the models validity;\n",
    "* Compute the RMSE on the test set and compare the performance with the linear models and the ridge regression models.\n",
    "\n",
    "### Relevant Examples\n",
    "\n",
    "The second linear regression example, ``CAB420_Regression_Example_2_Regularised_Regression.ipynb`` is a useful starting point here. You may also find the third linear regression example, ``CAB420_Regression_Example_3_Regression_with_Less_Data.ipynb`` of use, however this contains the same relvant code (fitting linear and regularised regression).\n",
    "\n",
    "### Suggested Packages\n",
    "\n",
    "The following packages are suggested, however there are many ways to approach things in python, if you'd rather use different pacakges that's cool too.\n",
    "\n",
    "In particular with this pratical, you have a choice of whether you'd rather use sklearn or statsmodels for regression."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "autoscroll": false,
    "ein.hycell": false,
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/envs/cab420-env/lib/python3.9/site-packages/statsmodels/compat/pandas.py:61: FutureWarning: pandas.Int64Index is deprecated and will be removed from pandas in a future version. Use pandas.Index with the appropriate dtype instead.\n",
      "  from pandas import Int64Index as NumericIndex\n"
     ]
    }
   ],
   "source": [
    "# import all the important packages\n",
    "\n",
    "# numpy handles pretty much anything that is a number/vector/matrix/array\n",
    "import numpy as np\n",
    "# pandas handles dataframes (exactly the same as tables in Matlab)\n",
    "import pandas as pd\n",
    "# matplotlib emulates Matlabs plotting functionality\n",
    "import matplotlib.pyplot as plt\n",
    "# seaborn, because of excellent heatmaps\n",
    "import seaborn as sns;\n",
    "# stats models is a package that is going to perform the regression analysis\n",
    "from statsmodels import api as sm\n",
    "from scipy import stats\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "# can also use sklearn for our regression\n",
    "from sklearn.linear_model import LinearRegression, Lasso, Ridge\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "# os allows us to manipulate variables on out local machine, such as paths and environment variables\n",
    "import os\n",
    "# self explainatory, dates and times\n",
    "from datetime import datetime, date\n",
    "# a helper package to help us iterate over objects\n",
    "import itertools"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 1: Load and Pre-process the data\n",
    "\n",
    "Loading and pre-processing should follow the same process as the previous practical. This should:\n",
    "* load the data\n",
    "* split into train, validation and test and pull out X and Y arrays\n",
    "\n",
    "In this practical we also seek to overcomplicate our model, i.e. add higher order terms, etc, such that it overfits. To achieve this you could:\n",
    "* Use ``PolynomialFeatures`` which has been imported from ``sklearn.preprocessing``; or\n",
    "* Use the x2fx function below which replicates a similar function is MATLAB and provides a handy way of adding higher order terms.\n",
    "\n",
    "Maintain the original (unexpanded) copy of the data as a separate variable as well as the \"blown up\" version.\n",
    "\n",
    "You should also consider the issue of data standardisation. This will be useful for the regularised regression and should be done prior to Questions 2 and 3; but you may also wish to do this here such that you are using the same data throughout. A function for standardisation is provided below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "autoscroll": false,
    "ein.hycell": false,
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "def x2fx(x, model='quadratic'):\n",
    "  \"\"\"Will create a quadratic, interaction and linear\n",
    "  versions of our variable of interest\n",
    "\n",
    "  Similar to the `x2fx()` function in Matlab.\n",
    "\n",
    "  Written by Saullo G. P. Castro, from\n",
    "  https://stackoverflow.com/questions/26574998/is-there-an-equivalent-function-for-x2fx-in-numpy\n",
    "\n",
    "  Basically don't worry too much about how this func works. If I had to write it myself,\n",
    "  it would look a lot worse than this.\n",
    "\n",
    "  Args:\n",
    "    x (np.array):\n",
    "      Data set with columns as features (variables) that we \n",
    "      want to generate higher order terms for\n",
    "    model (str):\n",
    "      Determine linear, interaction, quadratic, purequadratic terms\n",
    " \n",
    "  Returns:\n",
    "    Array with higher order terms added as additional columns\n",
    "  \"\"\"\n",
    "  from itertools import combinations as comb\n",
    "  linear = np.c_[np.ones(x.shape[0]), x]\n",
    "  if model == 'linear':\n",
    "    return linear\n",
    "  if model == 'purequadratic':\n",
    "    return np.c_[linear, x**2]\n",
    "\n",
    "  interaction = np.vstack([x[:,i]*x[:,j] for i, j in\n",
    "                           comb(range(x.shape[1]), 2)]).T\n",
    "    \n",
    "  if model == 'interaction':\n",
    "    return np.c_[linear, interaction]\n",
    "  if model == 'quadratic':\n",
    "    return np.c_[linear, interaction, x**2]\n",
    "\n",
    "def standardise(data):\n",
    "  \"\"\" Standardise/Normalise data to have zero mean and unit variance\n",
    "\n",
    "  Args:\n",
    "    data (np.array):\n",
    "      data we want to standardise (usually covariates)\n",
    "\n",
    "    Returns:\n",
    "      Standardised data, mean of data, standard deviation of data\n",
    "  \"\"\"\n",
    "  mu = np.mean(data, axis=0)\n",
    "  sigma = np.std(data, axis=0)\n",
    "  scaled = (data - mu) / sigma\n",
    "  return scaled, mu, sigma"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Unnamed: 0  Rainfall amount (millimetres)        Date  \\\n",
      "0           0                            0.0  2014-01-01   \n",
      "1           1                            0.0  2014-01-02   \n",
      "2           2                            1.0  2014-01-03   \n",
      "3           3                            0.0  2014-01-04   \n",
      "4           4                            0.0  2014-01-05   \n",
      "\n",
      "   Maximum temperature (Degree C)  Daily global solar exposure (MJ/m*m)  \\\n",
      "0                            30.6                                  31.2   \n",
      "1                            31.8                                  23.4   \n",
      "2                            34.5                                  29.6   \n",
      "3                            38.7                                  30.5   \n",
      "4                            33.6                                  15.7   \n",
      "\n",
      "   North Brisbane Bikeway Mann Park Windsor Cyclists Outbound  \\\n",
      "0                                                NaN            \n",
      "1                                                NaN            \n",
      "2                                                NaN            \n",
      "3                                                NaN            \n",
      "4                                                NaN            \n",
      "\n",
      "   Jack Pesch Bridge Pedestrians Outbound  \\\n",
      "0                                     NaN   \n",
      "1                                     NaN   \n",
      "2                                     NaN   \n",
      "3                                     NaN   \n",
      "4                                     NaN   \n",
      "\n",
      "   Story Bridge East Pedestrian Inbound  \\\n",
      "0                                   0.0   \n",
      "1                                   0.0   \n",
      "2                                   0.0   \n",
      "3                                   0.0   \n",
      "4                                   0.0   \n",
      "\n",
      "   Kedron Brook Bikeway Lutwyche Pedestrians Outbound  \\\n",
      "0                                                NaN    \n",
      "1                                                NaN    \n",
      "2                                                NaN    \n",
      "3                                                NaN    \n",
      "4                                                NaN    \n",
      "\n",
      "   Kedron Brook Bikeway Mitchelton Pedestrian Outbound  ...  \\\n",
      "0                                                NaN    ...   \n",
      "1                                                NaN    ...   \n",
      "2                                                NaN    ...   \n",
      "3                                                NaN    ...   \n",
      "4                                                NaN    ...   \n",
      "\n",
      "   Story Bridge East Pedestrian Outbound  \\\n",
      "0                                    0.0   \n",
      "1                                    0.0   \n",
      "2                                    0.0   \n",
      "3                                    0.0   \n",
      "4                                    0.0   \n",
      "\n",
      "   North Brisbane Bikeway Mann Park Windsor Pedestrian Outbound  \\\n",
      "0                                                NaN              \n",
      "1                                                NaN              \n",
      "2                                                NaN              \n",
      "3                                                NaN              \n",
      "4                                                NaN              \n",
      "\n",
      "   Story Bridge West Cyclists Inbound  Bicenntenial Bikeway  \\\n",
      "0                                 0.0                3333.0   \n",
      "1                                 0.0                4863.0   \n",
      "2                                 0.0                3905.0   \n",
      "3                                 0.0                3066.0   \n",
      "4                                 0.0                4550.0   \n",
      "\n",
      "   Story Bridge East Cyclists Inbound  Bishop Street Pedestrians Inbound  \\\n",
      "0                                 0.0                                NaN   \n",
      "1                                 0.0                                NaN   \n",
      "2                                 0.0                                NaN   \n",
      "3                                 0.0                                NaN   \n",
      "4                                 0.0                                NaN   \n",
      "\n",
      "   Story Bridge West Cyclists Outbound  \\\n",
      "0                                  0.0   \n",
      "1                                  0.0   \n",
      "2                                  0.0   \n",
      "3                                  0.0   \n",
      "4                                  0.0   \n",
      "\n",
      "   North Brisbane Bikeway Mann Park Windsor Pedestrian Inbound  \\\n",
      "0                                                NaN             \n",
      "1                                                NaN             \n",
      "2                                                NaN             \n",
      "3                                                NaN             \n",
      "4                                                NaN             \n",
      "\n",
      "   Kedron Brook Bikeway Mitchelton Pedestrian Inbound  \\\n",
      "0                                                NaN    \n",
      "1                                                NaN    \n",
      "2                                                NaN    \n",
      "3                                                NaN    \n",
      "4                                                NaN    \n",
      "\n",
      "   Schulz Canal Bridge Cyclists Inbound  \n",
      "0                                  92.0  \n",
      "1                                 123.0  \n",
      "2                                  77.0  \n",
      "3                                  57.0  \n",
      "4                                  92.0  \n",
      "\n",
      "[5 rows x 57 columns]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(1460, 57)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# load the data and split into train, validation, and test set\n",
    "def load_data():\n",
    "    data =  pd.read_csv(\"./combined.csv\")\n",
    "    print(data.head())\n",
    "    M_train = int(data.shape[0] * 0.8)\n",
    "    M_validation = int(data.shape[0] * 0.1)\n",
    "    M_test = int(data.shape[0] * 0.1)\n",
    "    X = []\n",
    "    Y = []\n",
    "    X.append(data.iloc[:M_train])\n",
    "    X.append(data.iloc[:M_train])\n",
    "\n",
    "\n",
    "    return X, Y\n",
    "\n",
    "X,Y = load_data()\n",
    "X[0].shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 2 (Question 1): Fit the Linear Model\n",
    "\n",
    "Fit a linear model to your data. Fit a model to both the original (i.e. without higher order terms) and expanded versions of the data to observe how severe the overfitting is.\n",
    "\n",
    "Be sure to evaluate the models on the validation and test sets. You should also consider qq-plots and $R^2$ values when inspecting the model's performance. To maximise code re-use, you may wish to write a function that takes a model, and various datasets (train, validation and test) as input, and calculates relevant performance measures. Some functions to compute performance measures are given below. Remember that $R^2$ should only be computed on the training set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "autoscroll": false,
    "ein.hycell": false,
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "def rmse(actual, pred):\n",
    "  return np.sqrt(mean_squared_error(actual, pred))\n",
    "\n",
    "def r_squared(actual, predicted):\n",
    "  r2 = r2_score(actual, predicted)\n",
    "  return r2\n",
    "\n",
    "def adj_r2(actual, predicted, n, p):\n",
    "  r2 = r2_score(actual, predicted)\n",
    "  adjr2 = 1 - (1 - r2) * (n - 1) / (n - p - 1);\n",
    "  return adjr2\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "source": [
    "### Step 3 (Question 2): Fit the Ridge Model\n",
    "\n",
    "Fit a ridge model to your data.\n",
    "\n",
    "It's recommended to use standardised data here, if you aren't already doing so.\n",
    "\n",
    "The key consideration here is your value of $\\lambda$. A good process to follow will be:\n",
    "* Select a range of $\\lambda$ values to consider. I would suggest using something like ``alpha_list = np.linspace(0, 10.0, 1000)``. Note that ``lambda`` is a keyword in python, hence we are calling this ``alpha`` here.\n",
    "* Loop over the values of $\\lambda$, i.e. ``for alpha in alpha_list:``\n",
    "  * For each value of $\\lambda$, fit a regression model\n",
    "  * Get the RMSE on the validation set. You may also wish to compute:\n",
    "    * RMSE on the training set\n",
    "    * $R^2$ on the training set\n",
    "* Find the value of $\\lambda$ that minimises the RMSE on the validation set\n",
    "\n",
    "If your best value of $\\lambda$ is $0$, you need to select a smaller step in your list of values, (i.e. in the above example we'd change this to ``alpha_list = np.linspace(0, 0.1, 10.0)``). If your best value is equal the maximum value in your range, then you need to search over a larger area (i.e. in the above example change it to ``alpha_list = np.linspace(0, 50.0, 10000)``). You may also want to refine your estimate, without making the search space huge. To do this, let's say the you get a value of $\\lambda$ of 100, using the above ``linspace``. In this case you could search around the following: ``alpha_list = np.linspace(90.0, 0.1, 110.0)``.\n",
    "\n",
    "Once you've found your value of $\\lambda$, fit the final model, evaluate it as you did for the linear model, and compare the results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "autoscroll": false,
    "ein.hycell": false,
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "source": [
    "### Step 4 (Question 3): Fit the LASSO Model\n",
    "\n",
    "Fit a LASSO model to your data.\n",
    "\n",
    "Your approach here should really follow what you've done for ridge. You should be able to copy and paste except:\n",
    "* Change your range of $\\lambda$ values. The same values that worked for Ridge will not be optimal here\n",
    "* Change the regression function that you are calling. If you are using sklearn, this means swapping ``sklearn.linear_model.Ridge`` for ``sklearn.linear_model.Lasso``. If you are using statsmodels, this means that when you call ``fit_regularized`` you pass in ``L1_wt=1``.\n",
    "\n",
    "Notes regarding $\\lambda$ values as the same as for Ridge regression.\n",
    "\n",
    "Once you have your final value of $\\lambda$, evaluate the model and compare to the others."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  },
  "name": "tute_2.ipynb"
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
