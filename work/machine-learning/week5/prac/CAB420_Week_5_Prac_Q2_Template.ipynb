{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CAB420, Week 5 Practical, Question 2 Template\n",
    "\n",
    "## Data Augmentation. \n",
    "\n",
    "The Houses dataset contains about 500 sets of images of houses, and the corresponding price of those houses. There are a number of images for each house, with images covering the front, bathroom, kitchen and bedroom. Ordinarily, this would be too little data to train a deep neural network, however data augmentation offers one way to try to overcome this. Using this dataset, design and train a model to predict the house price from an image. In doing this you should:\n",
    "* Design a simple network for this task, bearing in mind that you have limited data. While you may wish to fine-tune from a dataset such as CIFAR, note that this will restrict you to images of size 32 × 32 (unless you make larger changes to the network)\n",
    "* Divide the dataset into appropriate training and testing splits.\n",
    "* Set appropriate data augmentation parameters to generate additional samples.\n",
    "* Train the network and evaluate it’s performance. You may also which to consider which images to use. Using all images obviously leads to more data, but also increases the problem space, while using only (for example) frontal images may make the task easier as the network only needs to learn information relative to the front of the house.\n",
    "\n",
    "### Relevant Examples\n",
    "\n",
    "The sixth DCNN example, ``CAB420_DCNNs_Example_6_Fine_Tuning_and_Data_Augmentation.ipynb`` is a good starting point, and deals with fine-tuning.\n",
    "\n",
    "The two \"Lots of\" scripts, ``CAB420_DCNN_Models_Additional_Script_Lots_of_ResNet_Models.ipynb`` and ``CAB420_DCNN_Models_Additional_Script_Lots_of_VGG_Like_Models.ipynb`` produce lots of pre-trained models that you can use. Saved models that result for both of theses scripts are up on blackboard.\n",
    "\n",
    "### Suggested Packages\n",
    "\n",
    "Once again it's tensor flow and keras here. sklearn and matplotlib provide some supporting functionality."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "# why is this here? This is disabling some tensorflow warning I get in some of my environments that \n",
    "# annoy me (look ugly and untidy really)\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '1'\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import scipy.io\n",
    "import numpy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 1: Load and Prepare Data\n",
    "\n",
    "#### Frontal Images Only, or use all images?\n",
    "\n",
    "You can the images in different ways. Here, we provide code to load either the frontal data, or all data.\n",
    "\n",
    "Comment out/delete the one that you don't wish to use. You can also change your training/testing split sizes as you wish."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "houses_data = scipy.io.loadmat('../../data/Houses/houses_frontal.mat')\n",
    "train = houses_data['images_frontal'][:,:,:,0:450]\n",
    "train = numpy.transpose(train, (3, 0, 1, 2))\n",
    "train_y = houses_data['costs_frontal'][0:450]\n",
    "test = houses_data['images_frontal'][:,:,:,450:]\n",
    "test = numpy.transpose(test, (3, 0, 1, 2))\n",
    "test_y = houses_data['costs_frontal'][450:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "houses_data = scipy.io.loadmat('../../data/Houses/houses_all.mat')\n",
    "train = houses_data['images_all'][:,:,:,0:1800]\n",
    "train = numpy.transpose(train, (3, 0, 1, 2))\n",
    "train_y = houses_data['costs_all'][0:1800]\n",
    "test = houses_data['images_all'][:,:,:,1800:]\n",
    "test = numpy.transpose(test, (3, 0, 1, 2))\n",
    "test_y = houses_data['costs_all'][1800:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 2: The Network\n",
    "\n",
    "Build your network here. Things you should consider here include:\n",
    "* What size inputs do you have? How many layers/what size filters do you need for later layers to be able to see a large potion of the image (large receptive field)\n",
    "  * By default, the images will be 100x60, but you can resize them.\n",
    "  * Smaller images will mean you can process faster (and more easily build a deeper network), but you will lose fine grained information. There is a trade-off here that is interesting to explore. One other factor to add into this mix is that you can crop the images, i.e. crop out a smaller region and reduce the image size this way.  \n",
    "* How powerful is your computer? If you are running on CPU, keep the network simple (fewer layers, lower numbers of filters)\n",
    "* What is your network output? What size should the output be, and what loss should you be using?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (740795493.py, line 8)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"/tmp/ipykernel_11733/740795493.py\"\u001b[0;36m, line \u001b[0;32m8\u001b[0m\n\u001b[0;31m    outputs =\u001b[0m\n\u001b[0m              ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "def CreateModel():\n",
    "    # input in an image shape - if you resize the images change the input shape\n",
    "    inputs = keras.Input(shape=(60, 100, 3, ), name='img')\n",
    "\n",
    "    # add you layers here\n",
    "\n",
    "    # create the output\n",
    "    outputs = \n",
    "\n",
    "    # build and return the model\n",
    "    model_cnn = keras.Model(inputs=inputs, outputs=outputs, name='house_price_guide')\n",
    "    return model_cnn \n",
    "\n",
    "# use CreateModel to build your network"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 3: Setup Augmentation\n",
    "\n",
    "Refer to the lecture example and use the ImageDataGenerator. You should consider:\n",
    "* what augmentations make sense here?\n",
    "* what range of values is reasonable\n",
    "\n",
    "Be sure to visualise your augmentation results before proceeding."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 4: Train and evalute your model\n",
    "\n",
    "You may also wish to train different versions with different amounts of augmentation to see what impact this has. A simple evaluation function to plot some results is shown below. This will:\n",
    "* Plot training and validation loss, to help decide if you've trained the model for long enough. You could add in other metrics here depending on what you ask Keras to monitor\n",
    "* Plot a bar chart, that will show predicted and actual house values. You could visualise this in a bunch of ways. A scatter plot of predcited vs actual would be a good one to look at\n",
    "\n",
    "You could also consider measures like $R^2$ here. This is a regression model after all (regress to a house price from an image). Remember that $R^2$ can only be computed on the training set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def eval(model_cnn, history, test, test_y):\n",
    "    fig = plt.figure(figsize=[20, 6])\n",
    "    ax = fig.add_subplot(1, 1, 1)\n",
    "    ax.plot(history['loss'], label=\"Training Loss\")\n",
    "    ax.plot(history['val_loss'], label=\"Validation Loss\")\n",
    "    ax.legend()\n",
    "    \n",
    "    fig = plt.figure(figsize=[20, 6])\n",
    "    ax = fig.add_subplot(1, 1, 1)\n",
    "    w = 0.4\n",
    "    pos = numpy.arange(0, numpy.shape(test_y)[0], 1)\n",
    "    ax.bar(pos-w, test_y[:,0], label=\"Actual\", width=w)\n",
    "    pred = model_cnn.predict(test)\n",
    "    ax.bar(pos, pred[:,0], label=\"Predicted\", width=w)\n",
    "    ax.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
